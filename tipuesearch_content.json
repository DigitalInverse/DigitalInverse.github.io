{"pages":[{"url":"http://digitalinverse.github.io/pages/about.html","text":"My dearest reader, welcome to my shiny new blog! I'm yet another hacker, maverick, bibliophile, and INTJ . In my spare time I enjoy cooking and I'm an aspiring hobby photographer, and, yeah, I'm madly in love with Hanna! I am currently busy with life and stuff, but from time to time I will write a post about something that interests me. More than you ever wanted to know about me I received the MS degree in electrical engineering from Chalmers University of Technology , Gothenburg, Sweden, in 1996. In 1997, I was working with micro-lithography technology in Stockholm and Tokyo. I returned to academia and Chalmers in 1998, spent the 2000-2001 academic year as a Sweden-America Foundation Fellow at the University of Southern California , Los Angeles, California, before I eventually received my PhD degree in electrical engineering from Chalmers in 2003, with a dissertation on detection algorithms for wireless communications. I continued to follow a nonlinear trajectory to Los Alamos National Laboratory , Los Alamos, New Mexico, where I was promoted to Team Leader, conducting research on analysis and modeling of large-scale socio-technical systems. After five years, I once again moved to Gothenburg (which seems to be a strange attractor for me), where I took up a job as a Systems Manager at Ericsson , developing baseband algorithms for the base station uplink. I have written about 40 papers in the general areas of information theory, computer science, computer engineering, and discrete mathematics, most of which can be downloaded from ResearchGate . My Erdős number is three, by the chain Paul Erdős (0) - Vance Faber (1) - Madhav Marathe (2) and Christopher Barrett (2) - me (3).","tags":"pages","title":"About"},{"url":"http://digitalinverse.github.io/pages/colophon.html","text":"This blog is generated by Pelican , which takes great advantage of Python . The design is a minor twist on the zurb-F5-basic Pelican theme , adopting typefaces Open Sans by Steve Matteson , Tangerine by Omagari Toshi , and Sigmar One by Vernon Adams , all available on Google Fonts . The content is written in Markdown . Mathematical notation is expressed in LaTeX markup and rendered by the MathJax JavaScript engine (via the render_math Pelican plugin). Source code is highlighted by Pygments , using a slightly modified version of Solarized Light . Tipue Search was used to add search capabilities to this blog. Blog comments are handled with the help of Disqus . Images are downloaded from Death to the Stock Photo , unless otherwise specified. Hosted on GitHub thanks to GitHub Pages . Mostly written on my MacBook Pro and my iMac.","tags":"pages","title":"Colophon"},{"url":"http://digitalinverse.github.io/latex.html","text":"Fonts I assume you are already familiar with LaTeX , which is the de facto typesetting system for scientific documentation. LaTeX was developed by Turing Award recipient Leslie Lamport and builds on fellow Turing Award winner Donald Knuth 's typesetting system TeX. LaTeX encourages authors not to worry too much about the appearance of their documents but to concentrate on getting the right content. In line with this honorable philosophy, LaTeX provides a small set of fonts, notably Computer Modern, and back in the day, LaTeX users could not easily access all fonts available on their computer. Sure, you only need so many fonts , and Computer Modern is a very good font, but it is used so much I find it tiresome. This is where XeLaTeX comes to rescue! XeLaTeX is an option in the latest versions of standard LaTeX editors such as Texmaker . References BibLaTeX Images TikZ Standard Template Here is what my typical LaTeX-document looks like \\documentclass [11pt] { article } % setup fonts \\usepackage { fontspec } \\defaultfontfeatures { Ligatures=TeX } \\setromanfont { Palatino } % setup hyperlinks \\usepackage { hyperref } \\usepackage { xcolor } \\hypersetup { colorlinks, linkcolor= { blue!90!black } , citecolor= { blue!90!black } , urlcolor= { blue!90!black } } % setup front matter \\author { Anders Hansson } \\title { My Standard \\LaTeX\\ Template } % setup headers and footers \\usepackage { fancyhdr } \\pagestyle { fancy } \\fancyhead {} \\fancyfoot {} \\fancyhead [R] { \\thepage } % setup bibliography \\usepackage [style=ieee, url=true, hyperref=true, sorting=none, maxnames=99, backend=bibtex8] { biblatex } \\addbibresource { references.bib } % setup math \\usepackage { amsmath } \\usepackage { amssymb } % setup vector graphics drawing \\usepackage { tikz } \\begin { document } \\maketitle \\begin { abstract } Here goes the abstract. \\end { abstract } \\clearpage \\tableofcontents \\clearpage \\section { Introduction } \\href { http://julialang.org/ }{ Julia } is a high-level, high-performance dynamic programming language for technical computing, with syntax that is similar to MATLAB. See Fig.~ \\ref { fig:image } for an illustrative example of a person playing a brass instrument. David Barber has written a textbook on probabilistic inference in graphical models \\cite { barber } . An MMSE estimate $ \\hat {u}_k $ of the quantity measured by sensor $ k $ can be expressed as the quantized value corresponding to index $ i_k $ , which we denote $ \\tilde {u} ( i_k ) $ , conditioned on the total observation vector $ { \\bf y}_ 1 &#94;K $ , \\begin { align } \\label { eq:mmse } \\hat { u }_ k & = E \\{\\tilde { u } (i _ k)| { \\bf y }_ 1 &#94; K \\} = \\sum _{ \\forall i \\in \\mathcal { A }} \\tilde { u } (i) \\Pr (i _ k=i| { \\bf y }_ 1 &#94; K) \\nonumber\\\\ & = \\frac { 1 }{ p( { \\bf y }_ 1 &#94; K) } \\sum _{ \\forall i \\in\\mathcal { A }} \\tilde { u } (i) \\sum _{ \\forall { \\bf i }_ 1 &#94; K \\in\\mathcal { A }&#94; K : i _ k=i } \\Pr ( { \\bf i }_ 1 &#94; K) \\: p( { \\bf y }_ 1 &#94; K| { \\bf i }_ 1 &#94; K). \\end { align } Equation ( \\ref { eq:mmse } ) follows directly from Bayes' rule. \\bigskip\\bigskip \\begin { figure } [h] \\begin { center } \\includegraphics [width=0.8\\textwidth] { image.png } \\end { center } \\caption { This picture was photographed by \\href { http://gratisography.com }{ Ryan McGuire } and is free of copyright restrictions. } \\label { fig:image } \\end { figure } \\begin { figure } [h] \\begin { center } \\begin { tikzpicture } \\draw [draw=black, fill=green, fill opacity=0.2] (0,0) -- (0.5,1.5) -- (3,2) -- cycle; \\draw [<->,thick] (0,2.5) node (yaxis) [above] { $ y $ } |- (3.5,0) node (xaxis) [right] { $ x $ } ; \\end { tikzpicture } \\end { center } \\caption { This image was created with the help of \\href { http://www.texample.net/tikz }{ TikZ } . } \\end { figure } \\clearpage \\printbibliography [heading=bibintoc] \\end { document } which results in the PDF file . Formatting KOMA-Script is a great bundle of LaTeX classes and packages. I have used the article class scrartcl and the letter class scrlttr2 . Multi-Target Markdown DocOnce Sweave RStudio Presentation The Beamer LaTeX class can be used for producing slides. Matthias Vogelgesang has created a nice Beamer theme, mtheme , which tries to minimize visual noise.","tags":"Tech","title":"LaTeX in the 21st Century"},{"url":"http://digitalinverse.github.io/python.html","text":"Background","tags":"Tech","title":"Python Snippets"},{"url":"http://digitalinverse.github.io/akaike.html","text":"Background Akaike in the Context of Channel Estimation The model family under consideration is $$ y_n = h_n + u_n,$$ where \\(y_n\\) is an estimate of the \\(n\\) th tap of the true channel impulse response, \\(h_n\\) is the \\(n\\) th tap of the true channel impulse response, and the estimation error is modeled as a zero-mean Gaussian, i.e., \\(u_n \\sim N(0,\\sigma&#94;2)\\) . Furthermore, the model assumes that there are only \\(L\\) true taps, and our objective is to find the optimum channel length \\(L\\) . Recall the expression of the Akaike weight in (\\ref{eq:akaike}) and start by writing down the negative natural logarithm of the likelihood function, \\begin{align} -\\ln(\\Lambda) &= -\\ln\\left[\\frac{1}{\\sqrt{(2\\pi\\sigma&#94;2)&#94;N}} \\exp\\left\\{-\\frac{1}{2\\sigma&#94;2}\\sum_{n=1}&#94;N(y_n - h_n)&#94;2\\right\\}\\right] \\label{eq:lambda}\\nonumber\\\\ &= \\frac{N}{2}\\ln(2\\pi\\sigma&#94;2) + \\frac{1}{2\\sigma&#94;2}\\left[\\sum_{n=1}&#94;N(y_n - h_n)&#94;2\\right]. \\end{align} Find the extremum point \\((\\{h_n&#94;{\\ast}\\},(\\sigma&#94;2)&#94;{\\ast})\\) by setting the partial derivatives to zero, \\begin{align} \\frac{\\partial}{\\partial h_n}(-\\ln(\\Lambda)) &= \\frac{1}{2\\sigma&#94;2}[2h_n - 2y_n] = 0 \\quad\\Rightarrow\\quad h_n&#94;{\\ast} = y_n. \\label{eq:hstar}\\\\ \\frac{\\partial}{\\partial \\sigma&#94;2}(-\\ln(\\Lambda)) &= \\frac{N}{2}\\cdot\\frac{2\\pi}{2\\pi\\sigma&#94;2} - \\frac{1}{2(\\sigma&#94;2)&#94;2}\\left[\\sum_{n=1}&#94;N(y_n - h_n)&#94;2\\right] \\nonumber\\\\ &= \\frac{1}{2\\sigma&#94;2}\\left[N - \\frac{1}{\\sigma&#94;2}\\sum_{n=1}&#94;N(y_n - h_n)&#94;2\\right] = 0 \\nonumber\\\\ \\Rightarrow\\quad (\\sigma&#94;2)&#94;{\\ast} &= \\frac{1}{N}\\sum_{n=1}&#94;N(y_n - h_n)&#94;2 \\label{eq:sstar}\\\\ &= \\frac{1}{N}\\left[\\underbrace{\\sum_{n=1}&#94;L(y_n - h_n)&#94;2}_{\\text{$=0$ since $h_n&#94;{\\ast}=y_n,n\\leq L$}} + \\sum_{n=L+1}&#94;N(y_n - h_n)&#94;2\\right] = \\frac{1}{N}\\sum_{n=L+1}&#94;N y_n&#94;2.\\nonumber \\end{align} If we plug in the solution (\\ref{eq:hstar}) and (\\ref{eq:sstar}) in (\\ref{eq:lambda}), we get \\begin{equation} -\\ln(\\Lambda_{\\max}) = \\frac{N}{2}\\ln\\left(\\frac{2\\pi}{N}\\sum_{n=L+1}&#94;N y_n&#94;2\\right) + \\frac{N}{2}, \\end{equation} and the Akaike weight becomes (from (\\ref{eq:akaike})) \\begin{equation} \\omega = 2L + N\\ln\\left(\\frac{2\\pi}{N}\\sum_{n=L+1}&#94;N y_n&#94;2\\right) + N. \\end{equation} Discard constant terms and divide each (remaining) term with \\(N\\) to arrive at an equivalent weight (i.e., a weight that would favor the same model) \\begin{equation} \\omega = \\frac{2L}{N} + \\ln\\left(\\sum_{n=L+1}&#94;N y_n&#94;2\\right). \\end{equation} A similar result holds for a complex channel impulse response---we could treat the real and imaginary parts separately and combine them at the end, \\begin{equation} \\omega = \\frac{4L}{N} + \\ln\\left(\\sum_{n=L+1}&#94;N |y_n|&#94;2\\right). \\end{equation} Finally, for DSP computation, it may be easier if we express the weight in linear scale, \\begin{equation}\\label{eq:as_equiv} \\omega = \\exp\\left(\\frac{4L}{N}\\right) \\sum_{n=L+1}&#94;N |y_n|&#94;2. \\end{equation} if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Science","title":"Model Selection based on the Akaike Information Criterion"},{"url":"http://digitalinverse.github.io/bp.html","text":"Background","tags":"Science","title":"Solving Linear Equations using Loopy Belief Propagation"}]}